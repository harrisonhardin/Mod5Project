{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Machine Learning, Random Forest Classification (Wine Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Main Dataset with Explicit OSEMN Delineation about Wine Reviews](#Wine-Description-Length-to-Classify-Point-Rating-and-Price)\n",
    "2. [Supplemental Dataset without Explicit OSEMN Delineation about Wine Chemistry](#Phenolics:-Wine-Classification-From-A-Chemistry-Perspective)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,Imputer,LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Description Length to Classify Point Rating and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import main wine dataset, set index to eliminate superfluous Primary Key Column\n",
    "winedf = pd.read_csv('wine-data/winemag-data-130k-v2.csv', index_col=0)\n",
    "winedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Total    Percent\n",
      "region_2               79460  61.136715\n",
      "designation            37465  28.825661\n",
      "taster_twitter_handle  31213  24.015357\n",
      "taster_name            26244  20.192197\n",
      "region_1               21247  16.347493\n",
      "price                   8996   6.921544\n",
      "province                  63   0.048472\n",
      "country                   63   0.048472\n",
      "variety                    1   0.000769\n"
     ]
    }
   ],
   "source": [
    "# function to investigate missing values in wine dataset \n",
    "def MissingValues(df): #creating the function\n",
    "    total = df.isnull().sum().sort_values(ascending = False) # getting the sum of null values and ordering\n",
    "    percent = (df.isnull().sum() / df.isnull().count() * 100 ).sort_values(ascending = False) #getting the percent and order of null\n",
    "    df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) # Concatenating the total and percent\n",
    "    print(df[~(df['Total'] == 0)])# Returning values of nulls different of 0\n",
    "    \n",
    "    return\n",
    "\n",
    "MissingValues(winedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                     63\n",
       "description                  0\n",
       "designation              37465\n",
       "points                       0\n",
       "price                     8996\n",
       "province                    63\n",
       "region_1                 21247\n",
       "region_2                 79460\n",
       "taster_name              26244\n",
       "taster_twitter_handle    31213\n",
       "title                        0\n",
       "variety                      1\n",
       "winery                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Full list of Features, with or without missing data\n",
    "winedf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Narrow down the data to my two features of interest and target variable, clean data\n",
    "winedf = winedf[['points', 'price', 'description']].copy()\n",
    "winedf = winedf.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(winedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I check for duplicates, which is often valuable, but in this case it reduces the dataset by a factor of 5\n",
    "# This removes too many values, will come back to if there is time\n",
    "# winedf = winedf[winedf.duplicated('description', keep=False)]\n",
    "\n",
    "# len(winedf) after duplicated removed = 20026, not worth performing this operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Some outliers to take note of\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "g = sns.regplot(x='points', y='price', data=winedf, x_jitter=True, fit_reg=False)\n",
    "g.set_title(\"Points/Price Distribution\", fontsize=20)\n",
    "g.set_xlabel(\"Points\", fontsize= 15)\n",
    "g.set_ylabel(\"Price\", fontsize= 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a new column which will be used in modeling\n",
    "#by getting the word count of each wine description as a variable\n",
    "winedf2 = winedf.assign(desc_length = winedf['description'].apply(len))\n",
    "winedf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare Description Length to Price\n",
    "plt.figure(figsize=(14,6))\n",
    "g = sns.regplot(x='desc_length', y='price', data=winedf2, fit_reg=False)\n",
    "g.set_title('Price by Description Length', fontsize=20)\n",
    "g.set_ylabel('Price(USD)', fontsize = 16) \n",
    "g.set_xlabel('Description Length', fontsize = 16)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This foreshadows that Classification may not be best model here. \n",
    "#A Linear Regression would likely be a more precise model, \n",
    "#but let's put it to a classification test to be sure\n",
    "plt.figure(figsize=(14,6))\n",
    "g = sns.boxplot(x='points', y='desc_length', data=winedf2)\n",
    "g.set_title('Description Length by Points', fontsize=20)\n",
    "g.set_ylabel('Description Length', fontsize = 16) # Y label\n",
    "g.set_xlabel('Points', fontsize = 16) # X label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphing to see how points are distributed visually, to get a better sense of how to group them when simplifying\n",
    "plt.figure(figsize=(16,6))\n",
    "g = sns.countplot(x='points', data=winedf)\n",
    "g.set_title(\"Points Distribution by Appearance in Dataset\", fontsize=20) \n",
    "g.set_xlabel(\"Points\", fontsize=15) \n",
    "g.set_ylabel(\"Count\", fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with so many points and prices can make modeling difficult. I will demonstrate this\n",
    "#with my first entry in the next section, but for now I will create some functions that help me\n",
    "#narrow down the points and prices\n",
    "\n",
    "#Method taking points as param and simplifying them into 5 categories\n",
    "def points_simplified(points):\n",
    "    if points < 84:\n",
    "        return 1\n",
    "    elif points >= 84 and points < 88:\n",
    "        return 2 \n",
    "    elif points >= 88 and points < 92:\n",
    "        return 3 \n",
    "    elif points >= 92 and points < 96:\n",
    "        return 4 \n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "#Method taking price as param, making binary split on 100, as this is an important\n",
    "#threshold in the wine industry on price versus quality\n",
    "def price_simplified(price):\n",
    "    if price < 100:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "#Applying transform method and assigning result to new column \"points_simplified\"\n",
    "winedf2 = winedf2.assign(points_simplified = winedf2['points'].apply(points_simplified))\n",
    "#Apply another transform method, assigning result to new column \"price_simplified\"\n",
    "winedf2 = winedf2.assign(price_simplified = winedf2['price'].apply(price_simplified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Visualize our two newly transformed variables \n",
    "\n",
    "#First, description length & points binned into 5 categories\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.boxplot(x='points_simplified', y='desc_length', data=winedf2)\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Description Length per Points', fontweight=\"bold\", size=25) \n",
    "ax.set_ylabel('Description Length', fontsize = 25)\n",
    "ax.set_xlabel('Points', fontsize = 25) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Then, the price binary\n",
    "fig, ax = plt.subplots(figsize=(30,10))\n",
    "sns.boxplot(x='price_simplified', y='desc_length', data=winedf2)\n",
    "plt.xticks(fontsize=20) # X Ticks\n",
    "plt.yticks(fontsize=20) # Y Ticks\n",
    "ax.set_title('Description Length per Price', fontweight=\"bold\", size=25) \n",
    "ax.set_ylabel('Description Length', fontsize = 25)\n",
    "ax.set_xlabel('Price', fontsize = 25) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points/Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#First, I try the Random Forest Classifier model without any kind of scaling simply to demonstrate \n",
    "#the need both for scaling and for creating the simplifications I made in my EDA section above\n",
    "\n",
    "# Training the model\n",
    "X = winedf2.iloc[:,-1:] # This is the last column I created above, desc_length for description length\n",
    "y = winedf2['points']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "# Very imprecise.\n",
    "print(classification_report(y_test, predictions))\n",
    "#Very inaccurate\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training the model\n",
    "# X = desc_length \n",
    "#(our same X from before)\n",
    "y = winedf2['points_simplified'] # and simplified points\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the wine description length\n",
    "scaler=MinMaxScaler()\n",
    "scaled_wine=scaler.fit_transform(winedf2[['desc_length']])\n",
    "foo=pd.DataFrame(scaled_wine)\n",
    "X=foo[0]\n",
    "y=winedf2.points_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scaling the wine description length gives a negligible performance boost\n",
    "scaler=MinMaxScaler()\n",
    "scaled_wine=scaler.fit_transform(winedf2[['desc_length']])\n",
    "newdf=pd.DataFrame(scaled_wine)\n",
    "X=newdf[0]\n",
    "y=winedf2.points_simplified\n",
    "\n",
    "# Training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price/Description Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#As long as you are predicting for wines below $100, this is an excellent classifier\n",
    "X = winedf2.desc_length\n",
    "y = winedf2.price_simplified\n",
    "# Training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(np.array(y_test).reshape(-1,1), predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I use MinMax scaling in my analysis here, but Standard scaling gives comparable \n",
    "#albeit slightly less accuracy/precision in training/testing performed outside of this notebook\n",
    "scaler=MinMaxScaler()\n",
    "scaled_wine=scaler.fit_transform(winedf2[['desc_length']])\n",
    "newdf=pd.DataFrame(scaled_wine)\n",
    "X=newdf[0]\n",
    "y=winedf2.price_simplified\n",
    "# Training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "print(classification_report(np.array(y_test).reshape(-1,1), predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying to exclude some of the extreme upper outliers for price\n",
    "#This makes the model much less accurate. I will reflect on possible reasons in the next section\n",
    "y = winedf2[winedf2['price'] <= 500]['price']\n",
    "X = winedf2[winedf2['price'] <= 500]['desc_length']\n",
    "# Training the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(X_train).reshape(-1,1), np.array(y_train).reshape(-1,1))\n",
    "\n",
    "# Testing the model\n",
    "predictions = rfc.predict(np.array(X_test).reshape(-1,1))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description Length to Classify Points:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A possible explanation for the unsimplified points versus description length model\n",
    "# could be that I am using a classification model, Random Forest, versus Linear Regression. The data still is somewhat\n",
    "# linear after simplification of points into 5 categories, but I think classification holds up better\n",
    "# because there is less noise from the presence of fewer categories in the dependent variable.\n",
    "\n",
    "# That being said, this improvement in performance only brought the model to an only slightly better than chance\n",
    "# level of accuracy and precision. I would maintain that linear regression is probably the way to go here,\n",
    "# but this of course merits further testing to say for sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description Length to Classify Price:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving on to an interpretation of my price as dependent variable model, the most notable thing to mention is that\n",
    "# the model is highly accurate for wines underneath $100. It is not accurate above that, something I tried to address \n",
    "# through going back to my EDA and determining where a good cutoff for outliers would be. I chose $500 in the previous \n",
    "# section as that cutoff. This was not a successful refinement of the model, and produced very low accuracy.\n",
    "\n",
    "# This was something I tested and tried to get working outside of this final notebook for the project, and did not \n",
    "# find eliminating outliers on at other prices produced any better outcomes. The model works reasonably well, but\n",
    "# only when dealing with the entire dataset and I am still uncertain as to how to interpret this.\n",
    "\n",
    "# Fortunately, I put forth that the vast majority of wine drinkers are never looking to spend more than $100 on \n",
    "# a bottle, or to do so only very infrequently. This model shows that wines of a certain description length from this \n",
    "# dataset are able to be classified with high precision and accuracy through the Random Forest Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken together, I contend that these two results should be interpreted to mean that buying wine with longer\n",
    "# description length that is still under $100 for the bottle is the best approach. Since it was the weaker model,\n",
    "# point rating should only be used as a secondary way to classify which are truly the best wines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phenolics: Wine Classification From A Chemistry Perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As I have already dilineated the five stages of the Data Science lifecycle (OSEMN), I will not do so here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import supplemental dataset about phenolics\n",
    "winedf1 = pd.read_csv('winequality-red.csv')\n",
    "winedf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful when defining number of estimators parameter later\n",
    "winedf1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empty DataFrame = no missing values, see previous dataset's scrubbing section for function\n",
    "MissingValues(winedf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This shows the best place to split on if wine is good or bad is just above 6, say 6.25\n",
    "plt.figure(figsize=(16,6))\n",
    "g = sns.countplot(x='quality', data=winedf1, palette='Set3')\n",
    "g.set_title(\"Quality Ratings\", fontsize=20) # Graph title\n",
    "g.set_xlabel(\"Quality on a scale from 3 to 8\", fontsize=15) #X-axis label\n",
    "g.set_ylabel(\"Count\", fontsize=15) #Y-axis label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Best cutoff point for my Trader Joe binary\n",
    "bins = (2, 6.5, 8)\n",
    "group_names = ['twobuckchuck', 'nottwobuckchuck']\n",
    "winedf1['quality'] = pd.cut(winedf1['quality'], bins = bins, labels = group_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_quality = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bad becomes 0 and good becomes 1 \n",
    "winedf1['quality'] = label_quality.fit_transform(winedf1['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All but two of the variables are distributed over a very small scale\n",
    "sns.factorplot(data=winedf1,kind='box',size=10,aspect=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's visualize how the dataset looks after scaling\n",
    "scaler=MinMaxScaler()\n",
    "scaled_df=scaler.fit_transform(winedf1)\n",
    "scaled_df = pd.DataFrame(scaled_df, columns=winedf1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seems to just inject more reducible error into model, although this will be tested\n",
    "sns.factorplot(data=scaled_df,kind='box',size=10,aspect=2.5)\n",
    "#Quality has successfully been binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All Features As X\n",
    "x_train,x_test,y_train,y_test=train_test_split(winedf1.drop('quality',axis=1),winedf1['quality'],test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All features very effective for classifying wine that is better than two-buck chuck\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating through to see the best score using a GridSearch 10 fold Cross-Validation\n",
    "params_dict={'n_estimators':[1599],'max_features':['auto','sqrt','log2']}\n",
    "clf_rf=GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),param_grid=params_dict,scoring='accuracy',cv=10)\n",
    "clf_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best training score\n",
    "clf_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual accuracy on test set\n",
    "pred=clf_rf.predict(x_test)\n",
    "accuracy_score(pred,y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the all-features model to see how it performs with MinMax Scaling\n",
    "scaler=MinMaxScaler()\n",
    "scaled_df=scaler.fit_transform(winedf1)\n",
    "X=scaled_df[:,:11]\n",
    "Y=winedf1['quality'].values\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still a very accurate classifier of wine that is of better quality than two-buck chuck\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating through to see the best score using a GridSearch 10 fold Cross-Validation\n",
    "params_dict={'n_estimators':[1599],'max_features':['auto','sqrt','log2']}\n",
    "clf_rf=GridSearchCV(estimator=RandomForestClassifier(n_jobs=-1),param_grid=params_dict,scoring='accuracy',cv=10)\n",
    "clf_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Best training score\n",
    "clf_rf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual accuracy on test set\n",
    "pred=clf_rf.predict(x_test)\n",
    "accuracy_score(pred,y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Whether dealing with \"good\" or \"bad\" wine, Random Forest is quite a precise and accurate Machine Learning classification model. It is particularly good at distinguising what makes a \"good\" wine (which I define as \"nottwobuckchuck\" below the Quality Ratings graph). \n",
    "\n",
    "##### Feature scaling is always something worth applying when analyzing datasets. However in this specific instance, all of the features were very uniform even before scaling. Just to be even more certain that the classification model is sound, I will perform some additional tests surrounding the free and total sulphur dioxide metrics and their interplay with performance, both with and without MinMax Scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with only free sulphur dioxide and total sulphur dioxide, the two standouts from my EDA\n",
    "x_train,x_test,y_train,y_test=train_test_split(winedf1.iloc[:,5:7],winedf1['quality'],test_size=0.25,random_state=42)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same two features tested with MinMax Scaling\n",
    "scaler=MinMaxScaler()\n",
    "scaled_df=scaler.fit_transform(winedf1)\n",
    "X=scaled_df[:,5:7]\n",
    "Y=winedf1['quality'].values\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with remaining variables (all with very flat boxplots/uniform distribution)\n",
    "x_train,x_test,y_train,y_test=train_test_split(winedf1.iloc[:,[0,1,2,3,4,7,8,9,10]], \\\n",
    "                                               winedf1['quality'],test_size=0.25,random_state=42)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now with scaling\n",
    "scaler=MinMaxScaler()\n",
    "scaled_df=scaler.fit_transform(winedf1)\n",
    "X=(scaled_df[:,[0,1,2,3,4,7,8,9,10]])\n",
    "Y=winedf1['quality'].as_matrix()\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(np.array(x_train), np.array(y_train))\n",
    "predictions = rfc.predict(np.array(x_test))\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Overall Accuracy: ', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scaling doesn't have a big impact due to how uniform the dataset already is beforehand. Taking the free and total sulphur columns out makes for a model that is good at classifying two-buck chuck and great at classifying high quality wine (non two-buck chuck)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
